# Introduction
Large Language Models (LLM) and AI chatbots have become more and more common in the last years, since their first developments in the 2010s. Even though the chatbot idea was nothing new, shifting from simple linguistic tasks using natural language programming to generative AI was a huge breakthrough in this field. After the introductions of the first real LLMs in 2018 by OpenAI and Google, GPT-1 and BERT respectively, the field has been evolving rapidly with the language models getting more and more natural, correct and smart every day. 
With this changing world; a lot of habits, lifestyles and systems started changing. As of 2025, within the blink of an eye, AI is able to create described images, create essays and even though it is out of the scope of this research, videos. However, to what extent are the AI models capable of doing these various tasks? How much have we progressed and how much do we still have to go to trust AI to do those tasks that were before done by human intelligence?
Unofficially, it can be seen that many students have already shifted from using traditional search engines to relying on AI agents -Large Language Models- for explanations for their university level lectures. So the next step is asking,  if students can trust AI for learning, can professors also use it to prepare complete lecture materials? While this promises efficiency and accessibility, there are still questions about the quality, reliability, and teaching value of AI generated materials. In this research we aimed to analyze the advantages and tradeoffs of such an approach using different criteria.
For this aim, we evaluated four different AI agents—ChatGPT, Perplexity, Le Chat, and DeepSeek—to understand their capabilities and limitations in generating lecture material for a technical university-level course for bachelor’s degree on cache memories for the Computer Architecture course. By comparing the outputs of different models in terms of content depth, clarity, diagram integration, and more, we aimed to assess whether current AI tools can produce material suitable for academic instruction.
